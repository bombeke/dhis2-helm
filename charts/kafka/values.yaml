## Kafka Default values
## @param global.imageRegistry Global Docker image registry
## @param global.imagePullSecrets Global Docker registry secret names as an array
## @param global.defaultStorageClass Global default StorageClass for Persistent Volume(s)

##
global:
  imageRegistry: ""
  ## E.g.
  ## imagePullSecrets:
  ##   - myRegistryKeySecretName
  ##
  imagePullSecrets: []
  defaultStorageClass: ""
  storageClass: ""
  ## Compatibility adaptations for Kubernetes platforms
  ##
  compatibility:
    ## Compatibility adaptations for Openshift
    ##
    openshift:
      ## @param global.compatibility.openshift.adaptSecurityContext Adapt the securityContext sections of the deployment to make them compatible with Openshift restricted-v2 SCC: remove runAsUser, runAsGroup and fsGroup and let the platform use their allowed default IDs. Possible values: auto (apply if the detected running cluster is Openshift), force (perform the adaptation always), disabled (do not perform adaptation)
      ##
      adaptSecurityContext: auto
## @section Common parameters
##

## @param kubeVersion Override Kubernetes version
##
kubeVersion: ""
## @param nameOverride String to partially override common.names.fullname
##
nameOverride: ""
## @param fullnameOverride String to fully override common.names.fullname
##
fullnameOverride: ""
## @param clusterDomain Default Kubernetes cluster domain
##
clusterDomain: cluster.local
## @param commonLabels Labels to add to all deployed objects
##
commonLabels: {}
## @param commonAnnotations Annotations to add to all deployed objects
##
commonAnnotations: {}
## @param extraDeploy Array of extra objects to deploy with the release
##
extraDeploy: []
## @param serviceBindings.enabled Create secret for service binding (Experimental)
## Ref: https://servicebinding.io/service-provider/
##
serviceBindings:
  enabled: false
## Enable diagnostic mode in the statefulset
##
diagnosticMode:
  ## @param diagnosticMode.enabled Enable diagnostic mode (all probes will be disabled and the command will be overridden)
  ##
  enabled: false
  ## @param diagnosticMode.command Command to override all containers in the statefulset
  ##
  command:
    - sleep
  ## @param diagnosticMode.args Args to override all containers in the statefulset
  ##
  args:
    - infinity
## @section Kafka parameters
##
## Bitnami Kafka image version
## ref: https://hub.docker.com/r/bitnami/kafka/tags/
## @param image.registry [default: REGISTRY_NAME] Kafka image registry
## @param image.repository [default: REPOSITORY_NAME/kafka] Kafka image repository
## @skip image.tag Kafka image tag (immutable tags are recommended)
## @param image.digest Kafka image digest in the way sha256:aa.... Please note this parameter, if set, will override the tag
## @param image.pullPolicy Kafka image pull policy
## @param image.pullSecrets Specify docker-registry secret names as an array
## @param image.debug Specify if debug values should be set
##
image:
  registry: docker.io
  repository: bitnami/kafka
  tag: 3.8.1-debian-12-r0
  digest: ""
  ## Specify a imagePullPolicy
  ## ref: https://kubernetes.io/docs/concepts/containers/images/#pre-pulled-images
  ##
  pullPolicy: IfNotPresent
  ## Optionally specify an array of imagePullSecrets.
  ## Secrets must be manually created in the namespace.
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
  ## e.g:
  ## pullSecrets:
  ##   - myRegistryKeySecretName
  ##
  pullSecrets: []
  ## Set to true if you would like to see extra information on logs
  ##
  debug: true

## @param log4j An optional log4j.properties file to overwrite the default of the Kafka brokers
## An optional log4j.properties file to overwrite the default of the Kafka brokers
## ref: https://github.com/apache/kafka/blob/trunk/config/log4j.properties
##
log4j: ""
## @param existingLog4jConfigMap The name of an existing ConfigMap containing a log4j.properties file
## The name of an existing ConfigMap containing a log4j.properties file
## NOTE: this will override `log4j`
##
existingLog4jConfigMap: ""

## JAVA CATALINA_OPTS
## Busiest recommended -Xmx6g -Xms6g -XX:MetaspaceSize=96m -XX:+UseG1GC
## -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:G1HeapRegionSize=16M
## -XX:MinMetaspaceFreeRatio=50 -XX:MaxMetaspaceFreeRatio=80 -XX:+ExplicitGCInvokesConcurrent

catalinaOpts: "-Xmx6g -Xms6g -XX:MetaspaceSize=96m -XX:+UseG1GC
-XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:G1HeapRegionSize=16M
-XX:MinMetaspaceFreeRatio=50 -XX:MaxMetaspaceFreeRatio=80 -XX:+ExplicitGCInvokesConcurrent"
replicaCount: 1

autoscaling:
  enabled: false

service:
  type: ClusterIP
  port: 8083
listeners:
  connect:
    port: 8083
  broker:
    port: 9092
  controller:
    port: 9093
  interbroker:
    port: 9094

ingress:
  enabled: false

connectors:
  - name: starrocks-kafka-connector
    config:
      connector.class: com.starrocks.connector.kafka.StarRocksSinkConnector
      topics: test
      key.converter: org.apache.kafka.connect.json.JsonConverter
      value.converter: org.apache.kafka.connect.json.JsonConverter
      key.converter.schemas.enable: true
      value.converter.schemas.enable: false
      starrocks.http.url: 192.168.9.10:8030
      starrocks.topic2table.map: "test:test_tbl"
      starrocks.username: user1
      starrocks.password: "123456"
      starrocks.database.name: example_db
      sink.properties.strip_outer_array: true

  - name: mongodb-source
    config:
      connection.uri: "mongodb://root:password@mongodb-hostname:27017"
      connector.class: com.mongodb.kafka.connect.MongoSourceConnector
      database: test
      collection: test
      output.format.value: json
      output.format.key: json
      key.converter.schemas.enable: "false"
      value.converter.schemas.enable: "false"
      key.converter: org.apache.kafka.connect.json.JsonConverter
      value.converter: org.apache.kafka.connect.json.JsonConverter

  - name: opensearch-sink
    config:
      connector.class: io.aiven.kafka.connect.opensearch.OpensearchSinkConnector
      tasks.max: 1
      topics: test-opensearch-sink
      key.ignore: "true"
      connection.url: "http://localhost:9200"
      type.name: kafka-connect
      index.write.method: upsert
      connection.username: admin
      connection.password: ""

  - name: milvus-connector
    config:
      public.endpoint: https://url
      connector.class: com.milvus.io.kafka.MilvusSinkConnector
      token: ""
      collection.name: topic_0
      topics: topic_0

kafka:
  enabled: true
  image:
    debug: true
  kraft:
    enabled: true
    clusterId: "my-kraft-cluster-id"

  ## Extra objects to deploy (value evaluated as a template)
  ##
  extraDeploy:
    - |
      {{- $replicaCount := int .Values.controller.replicaCount }}
      {{- if and .Values.kraft.enabled (or (gt $replicaCount 0) .Values.controller.autoscaling.enabled) }}
      apiVersion: {{ include "common.capabilities.statefulset.apiVersion" . }}
      kind: StatefulSet
      metadata:
        name: {{ printf "%s-controller-connect" (include "common.names.fullname" .) }}
        labels: {{- include "common.labels.standard" ( dict "customLabels" .Values.commonLabels "context" $ ) | nindent 4 }}
          app.kubernetes.io/component: controller-eligible
          app.kubernetes.io/part-of: kafka
        {{- if .Values.commonAnnotations }}
        annotations: {{- include "common.tplvalues.render" ( dict "value" .Values.commonAnnotations "context" $ ) | nindent 4 }}
        {{- end }}
      spec:
        podManagementPolicy: {{ .Values.controller.podManagementPolicy }}
        {{- if not .Values.controller.autoscaling.enabled }}
        replicas: 1
        {{- end }}
        {{- $podLabels := include "common.tplvalues.merge" ( dict "values" ( list .Values.controller.podLabels .Values.commonLabels ) "context" . ) }}
        selector:
          matchLabels: {{- include "common.labels.matchLabels" ( dict "customLabels" $podLabels "context" $ ) | nindent 6 }}
            app.kubernetes.io/component: controller-eligible
            app.kubernetes.io/part-of: kafka
        serviceName: {{ printf "%s-controller-headless" (include "common.names.fullname" .) | trunc 63 | trimSuffix "-" }}
        updateStrategy: {{- include "common.tplvalues.render" (dict "value" .Values.controller.updateStrategy "context" $ ) | nindent 4 }}
        {{- if and .Values.controller.minReadySeconds (semverCompare ">= 1.23-0" (include "common.capabilities.kubeVersion" .)) }}
        minReadySeconds: {{ .Values.controller.minReadySeconds }}
        {{- end }}
        template:
          metadata:
            labels: {{- include "common.labels.standard" ( dict "customLabels" $podLabels "context" $ ) | nindent 8 }}
              app.kubernetes.io/component: controller-eligible
              app.kubernetes.io/part-of: kafka
            annotations:
              {{- if (include "kafka.controller.createConfigmap" .) }}
              checksum/configuration: {{ include (print $.Template.BasePath "/controller-eligible/configmap.yaml") . | sha256sum }}
              {{- end }}
              {{- if (include "kafka.createSaslSecret" .) }}
              checksum/passwords-secret: {{ include (print $.Template.BasePath "/secrets.yaml") . | sha256sum }}
              {{- end }}
              {{- if (include "kafka.createTlsSecret" .) }}
              checksum/tls-secret: {{ include (print $.Template.BasePath "/tls-secret.yaml") . | sha256sum }}
              {{- end }}
              {{- if (include "kafka.metrics.jmx.createConfigmap" .) }}
              checksum/jmx-configuration: {{ include (print $.Template.BasePath "/metrics/jmx-configmap.yaml") . | sha256sum }}
              {{- end }}
              {{- if .Values.controller.podAnnotations }}
              {{- include "common.tplvalues.render" (dict "value" .Values.controller.podAnnotations "context" $) | nindent 8 }}
              {{- end }}
          spec:
            {{- include "kafka.imagePullSecrets" . | nindent 6 }}
            automountServiceAccountToken: {{ .Values.controller.automountServiceAccountToken }}
            {{- if .Values.controller.hostAliases }}
            hostAliases: {{- include "common.tplvalues.render" (dict "value" .Values.controller.hostAliases "context" $) | nindent 8 }}
            {{- end }}
            hostNetwork: {{ .Values.controller.hostNetwork }}
            hostIPC: {{ .Values.controller.hostIPC }}
            {{- if .Values.controller.schedulerName }}
            schedulerName: {{ .Values.controller.schedulerName | quote }}
            {{- end }}
            {{- if .Values.controller.affinity }}
            affinity: {{- include "common.tplvalues.render" (dict "value" .Values.controller.affinity "context" $) | nindent 8 }}
            {{- else }}
            affinity:
              podAffinity: {{- include "common.affinities.pods" (dict "type" .Values.controller.podAffinityPreset "component" "controller-eligible" "customLabels" $podLabels "context" $) | nindent 10 }}
              podAntiAffinity: {{- include "common.affinities.pods" (dict "type" .Values.controller.podAntiAffinityPreset "component" "controller-eligible" "customLabels" $podLabels "context" $) | nindent 10 }}
              nodeAffinity: {{- include "common.affinities.nodes" (dict "type" .Values.controller.nodeAffinityPreset.type "key" .Values.controller.nodeAffinityPreset.key "values" .Values.controller.nodeAffinityPreset.values) | nindent 10 }}
            {{- end }}
            {{- if .Values.controller.nodeSelector }}
            nodeSelector: {{- include "common.tplvalues.render" (dict "value" .Values.controller.nodeSelector "context" $) | nindent 8 }}
            {{- end }}
            {{- if .Values.controller.tolerations }}
            tolerations: {{- include "common.tplvalues.render" (dict "value" .Values.controller.tolerations "context" $) | nindent 8 }}
            {{- end }}
            {{- if .Values.controller.topologySpreadConstraints }}
            topologySpreadConstraints: {{- include "common.tplvalues.render" (dict "value" .Values.controller.topologySpreadConstraints "context" $) | nindent 8 }}
            {{- end }}
            {{- if .Values.controller.terminationGracePeriodSeconds }}
            terminationGracePeriodSeconds: {{ .Values.controller.terminationGracePeriodSeconds }}
            {{- end }}
            {{- if .Values.controller.priorityClassName }}
            priorityClassName: {{ .Values.controller.priorityClassName }}
            {{- end }}
            {{- if .Values.controller.runtimeClassName }}
            runtimeClassName: {{ .Values.controller.runtimeClassName }}
            {{- end }}
            {{- if .Values.controller.podSecurityContext.enabled }}
            securityContext: {{- include "common.compatibility.renderSecurityContext" (dict "secContext" .Values.controller.podSecurityContext "context" $) | nindent 8 }}
            {{- end }}
            serviceAccountName: {{ include "kafka.serviceAccountName" . }}
            enableServiceLinks: {{ .Values.controller.enableServiceLinks }}
            {{- if .Values.dnsPolicy  }}
            dnsPolicy: {{ .Values.dnsPolicy }}
            {{- end }}
            {{- if .Values.dnsConfig }}
            dnsConfig: {{- include "common.tplvalues.render" (dict "value" .Values.dnsConfig "context" $) | nindent 8 }}
            {{- end }}
            initContainers:
              {{- if and .Values.volumePermissions.enabled .Values.controller.persistence.enabled }}
              - name: volume-permissions
                image: {{ include "kafka.volumePermissions.image" . }}
                imagePullPolicy: {{ .Values.volumePermissions.image.pullPolicy | quote }}
                command:
                  - /bin/bash
                args:
                  - -ec
                  - |
                    mkdir -p /opt/connectors
                    chown -R {{ .Values.controller.containerSecurityContext.runAsUser }}:{{ .Values.controller.podSecurityContext.fsGroup }} "{{ .Values.controller.persistence.mountPath }}" /opt/connectors
                    mkdir -p "{{ .Values.controller.persistence.mountPath }}" "{{ .Values.controller.logPersistence.mountPath }}"
                    chown -R {{ .Values.controller.containerSecurityContext.runAsUser }}:{{ .Values.controller.podSecurityContext.fsGroup }} "{{ .Values.controller.persistence.mountPath }}" "{{ .Values.controller.logPersistence.mountPath }}"
                    find "{{ .Values.controller.persistence.mountPath }}" -mindepth 1 -maxdepth 1 -not -name ".snapshot" -not -name "lost+found" | xargs -r chown -R {{ .Values.controller.containerSecurityContext.runAsUser }}:{{ .Values.controller.podSecurityContext.fsGroup }}
                    find "{{ .Values.controller.logPersistence.mountPath }}" -mindepth 1 -maxdepth 1 -not -name ".snapshot" -not -name "lost+found" | xargs -r chown -R {{ .Values.controller.containerSecurityContext.runAsUser }}:{{ .Values.controller.podSecurityContext.fsGroup }}
                {{- if eq ( toString ( .Values.volumePermissions.containerSecurityContext.runAsUser )) "auto" }}
                securityContext: {{- omit .Values.volumePermissions.containerSecurityContext "runAsUser" | toYaml | nindent 12 }}
                {{- else }}
                securityContext: {{- .Values.volumePermissions.containerSecurityContext | toYaml | nindent 12 }}
                {{- end }}
                {{- if .Values.volumePermissions.resources }}
                resources: {{- toYaml .Values.volumePermissions.resources | nindent 12 }}
                {{- else if ne .Values.volumePermissions.resourcesPreset "none" }}
                resources: {{- include "common.resources.preset" (dict "type" .Values.volumePermissions.resourcesPreset) | nindent 12 }}
                {{- end }}
                volumeMounts:
                  - name: data
                    mountPath: {{ .Values.controller.persistence.mountPath }}
                  - name: logs
                    mountPath: {{ .Values.controller.logPersistence.mountPath }}
                  - name: kafka-connectors
                    mountPath: /opt/connectors
              {{- end }}
              {{- if and .Values.externalAccess.enabled .Values.externalAccess.autoDiscovery.enabled (or .Values.externalAccess.controller.forceExpose (not .Values.controller.controllerOnly))}}
              {{- include "kafka.autoDiscoveryInitContainer" ( dict "role" "controller" "context" $) | nindent 8 }}
              {{- end }}
              {{- include "kafka.prepareKafkaInitContainer" ( dict "role" "controller" "context" $) | nindent 8 }}
              {{- include "kafka.prepareKafkaConnectInitContainer" ( dict "role" "controller" "context" $) | nindent 8 }}
              {{- if .Values.controller.initContainers }}
              {{- include "common.tplvalues.render" ( dict "value" .Values.controller.initContainers "context" $ ) | nindent 8 }}
              {{- end }}
              {{- if .Values.initContainers }}
              {{- include "common.tplvalues.render" ( dict "value" .Values.initContainers "context" $ ) | nindent 8 }}
              {{- end }}
            containers:
              - name: kafka
                image: {{ include "kafka.image" . }}
                imagePullPolicy: {{ .Values.image.pullPolicy | quote }}
                {{- if .Values.controller.containerSecurityContext.enabled }}
                securityContext: {{- include "common.compatibility.renderSecurityContext" (dict "secContext" .Values.controller.containerSecurityContext "context" $) | nindent 12 }}
                {{- end }}
                {{- if .Values.diagnosticMode.enabled }}
                command: {{- include "common.tplvalues.render" (dict "value" .Values.diagnosticMode.command "context" $) | nindent 12 }}
                {{- else if .Values.controller.command }}
                command: {{- include "common.tplvalues.render" (dict "value" .Values.controller.command "context" $) | nindent 12 }}
                {{- end }}
                {{- if .Values.diagnosticMode.enabled }}
                args: {{- include "common.tplvalues.render" (dict "value" .Values.diagnosticMode.args "context" $) | nindent 12 }}
                {{- else if .Values.controller.args }}
                args: {{- include "common.tplvalues.render" (dict "value" .Values.controller.args "context" $) | nindent 12 }}
                {{- end }}
                command: 
                  - /bin/bash
                args:
                  - -ec 
                  - |
                    /opt/bitnami/kafka/bin/connect-distributed.sh /opt/bitnami/kafka/config/connect-distributed.properties
                    /scripts-connect/kafka-connectors.sh

                env:
                  - name: BITNAMI_DEBUG
                    value: {{ ternary "true" "false" (or .Values.image.debug .Values.diagnosticMode.enabled) | quote }}
                  - name: KAFKA_HEAP_OPTS
                    value: {{ coalesce .Values.controller.heapOpts .Values.heapOpts | quote }}
                  - name: KAFKA_KRAFT_CLUSTER_ID
                    valueFrom:
                      secretKeyRef:
                        name: {{ default (printf "%s-kraft-cluster-id" (include "common.names.fullname" .)) .Values.kraft.existingClusterIdSecret }}
                        key: kraft-cluster-id
                  {{- if and (include "kafka.saslEnabled" .) (or (regexFind "SCRAM" (upper .Values.sasl.enabledMechanisms)) (regexFind "SCRAM" (upper .Values.sasl.controllerMechanism)) (regexFind "SCRAM" (upper .Values.sasl.interBrokerMechanism))) }}
                  - name: KAFKA_KRAFT_BOOTSTRAP_SCRAM_USERS
                    value: "true"
                  {{- if and (include "kafka.client.saslEnabled" . ) .Values.sasl.client.users (include "kafka.saslUserPasswordsEnabled" .) }}
                  - name: KAFKA_CLIENT_USERS
                    value: {{ join "," .Values.sasl.client.users | quote }}
                  - name: KAFKA_CLIENT_PASSWORDS
                    valueFrom:
                      secretKeyRef:
                        name: {{ include "kafka.saslSecretName" . }}
                        key: client-passwords
                  {{- end }}
                  {{- if regexFind "SASL" (upper .Values.listeners.interbroker.protocol) }}
                  {{- if (include "kafka.saslUserPasswordsEnabled" .) }}
                  - name: KAFKA_INTER_BROKER_USER
                    value: {{ .Values.sasl.interbroker.user | quote }}
                  - name: KAFKA_INTER_BROKER_PASSWORD
                    valueFrom:
                      secretKeyRef:
                        name: {{ include "kafka.saslSecretName" . }}
                        key: inter-broker-password
                  {{- end }}
                  {{- if (include "kafka.saslClientSecretsEnabled" .) }}
                  - name: KAFKA_INTER_BROKER_CLIENT_ID
                    value: {{ .Values.sasl.interbroker.clientId | quote }}
                  - name: KAFKA_INTER_BROKER_CLIENT_SECRET
                    valueFrom:
                      secretKeyRef:
                        name: {{ include "kafka.saslSecretName" . }}
                        key: inter-broker-client-secret
                  {{- end }}
                  {{- end }}
                  {{- if regexFind "SASL" (upper .Values.listeners.controller.protocol) }}
                  {{- if (include "kafka.saslUserPasswordsEnabled" .) }}
                  - name: KAFKA_CONTROLLER_USER
                    value: {{ .Values.sasl.controller.user | quote }}
                  - name: KAFKA_CONTROLLER_PASSWORD
                    valueFrom:
                      secretKeyRef:
                        name: {{ include "kafka.saslSecretName" . }}
                        key: controller-password
                  {{- end }}
                  {{- if (include "kafka.saslClientSecretsEnabled" .) }}
                  - name: KAFKA_CONTROLLER_CLIENT_ID
                    value: {{ .Values.sasl.controller.clientId | quote }}
                  - name: KAFKA_CONTROLLER_CLIENT_SECRET
                    valueFrom:
                      secretKeyRef:
                        name: {{ include "kafka.saslSecretName" . }}
                        key: controller-client-secret
                  {{- end }}
                  {{- end }}
                  {{- end }}
                  {{- if .Values.metrics.jmx.enabled }}
                  - name: JMX_PORT
                    value: {{ .Values.metrics.jmx.kafkaJmxPort | quote }}
                  {{- end }}
                  {{- if .Values.controller.extraEnvVars }}
                  {{- include "common.tplvalues.render" ( dict "value" .Values.controller.extraEnvVars "context" $) | nindent 12 }}
                  {{- end }}
                  {{- if .Values.extraEnvVars }}
                  {{- include "common.tplvalues.render" ( dict "value" .Values.extraEnvVars "context" $) | nindent 12 }}
                  {{- end }}
                {{- if or .Values.controller.extraEnvVarsCM .Values.extraEnvVarsCM .Values.controller.extraEnvVarsSecret .Values.extraEnvVarsSecret }}
                envFrom:
                  {{- if .Values.controller.extraEnvVarsCM }}
                  - configMapRef:
                      name: {{ include "common.tplvalues.render" (dict "value" .Values.controller.extraEnvVarsCM "context" $) }}
                  {{- end }}
                  {{- if .Values.extraEnvVarsCM }}
                  - configMapRef:
                      name: {{ include "common.tplvalues.render" (dict "value" .Values.extraEnvVarsCM "context" $) }}
                  {{- end }}
                  {{- if .Values.controller.extraEnvVarsSecret }}
                  - secretRef:
                      name: {{ include "common.tplvalues.render" (dict "value" .Values.controller.extraEnvVarsSecret "context" $) }}
                  {{- end }}
                  {{- if .Values.extraEnvVarsSecret }}
                  - secretRef:
                      name: {{ include "common.tplvalues.render" (dict "value" .Values.extraEnvVarsSecret "context" $) }}
                  {{- end }}
                {{- end }}
                ports:
                  - name: controller
                    containerPort: {{ .Values.listeners.controller.containerPort }}
                  {{- if not .Values.controller.controllerOnly }}
                  - name: client
                    containerPort: {{ .Values.listeners.client.containerPort }}
                  - name: interbroker
                    containerPort: {{ .Values.listeners.interbroker.containerPort }}
                  {{- if .Values.externalAccess.enabled }}
                  - name: external
                    containerPort: {{ .Values.listeners.external.containerPort }}
                  {{- end }}
                  {{- if .Values.listeners.extraListeners }}
                  {{- include "kafka.extraListeners.containerPorts" . | nindent 12 }}
                  {{- end }}
                  {{- end }}
                  {{- if .Values.controller.extraContainerPorts }}
                  {{- include "common.tplvalues.render" (dict "value" .Values.controller.extraContainerPorts "context" $) | nindent 12 }}
                  {{- end }}
                {{- if not .Values.diagnosticMode.enabled }}
                {{- if .Values.controller.customLivenessProbe }}
                livenessProbe: {{- include "common.tplvalues.render" (dict "value" .Values.controller.customLivenessProbe "context" $) | nindent 12 }}
                {{- else if .Values.controller.livenessProbe.enabled }}
                livenessProbe: {{- include "common.tplvalues.render" (dict "value" (omit .Values.controller.livenessProbe "enabled") "context" $) | nindent 12 }}
                  exec:
                    command:
                      - pgrep
                      - -f
                      - kafka
                {{- end }}
                {{- if .Values.controller.customReadinessProbe }}
                readinessProbe: {{- include "common.tplvalues.render" (dict "value" .Values.controller.customReadinessProbe "context" $) | nindent 12 }}
                {{- else if .Values.controller.readinessProbe.enabled }}
                readinessProbe: {{- include "common.tplvalues.render" (dict "value" (omit .Values.controller.readinessProbe "enabled") "context" $) | nindent 12 }}
                  tcpSocket:
                    port: "controller"
                {{- end }}
                {{- if .Values.controller.customStartupProbe }}
                startupProbe: {{- include "common.tplvalues.render" (dict "value" .Values.controller.customStartupProbe "context" $) | nindent 12 }}
                {{- else if .Values.controller.startupProbe.enabled }}
                startupProbe: {{- include "common.tplvalues.render" (dict "value" (omit .Values.controller.startupProbe "enabled") "context" $) | nindent 12 }}
                  tcpSocket:
                    port: "controller"
                {{- end }}
                {{- end }}
                {{- if .Values.controller.lifecycleHooks }}
                lifecycle: {{- include "common.tplvalues.render" (dict "value" .Values.controller.lifecycleHooks "context" $) | nindent 12 }}
                {{- end }}
                {{- if .Values.controller.resources }}
                resources: {{- toYaml .Values.controller.resources | nindent 12 }}
                {{- else if ne .Values.controller.resourcesPreset "none" }}
                resources: {{- include "common.resources.preset" (dict "type" .Values.controller.resourcesPreset) | nindent 12 }}
                {{- end }}
                volumeMounts:
                  - name: kafka-plugins
                    mountPath: /opt/bitnami/kafka/plugins
                  - name: kafka-connectors
                    mountPath: /opt/connectors
                  - name: data
                    mountPath: {{ .Values.controller.persistence.mountPath }}
                  - name: logs
                    mountPath: {{ .Values.controller.logPersistence.mountPath }}
                  - name: kafka-config
                    mountPath: /opt/bitnami/kafka/config/server.properties
                    subPath: server.properties
                  {{- if .Values.sasl.zookeeper.user }}
                  - name: kafka-config
                    mountPath: /opt/bitnami/kafka/config/kafka_jaas.conf
                    subPath: kafka_jaas.conf
                  {{- end }}
                  - name: tmp
                    mountPath: /tmp
                  {{- if or .Values.log4j .Values.existingLog4jConfigMap }}
                  - name: log4j-config
                    mountPath: /opt/bitnami/kafka/config/log4j.properties
                    subPath: log4j.properties
                  {{- end }}
                  {{- if or .Values.tls.zookeeper.enabled (include "kafka.sslEnabled" .) }}
                  - name: kafka-shared-certs
                    mountPath: /opt/bitnami/kafka/config/certs
                    readOnly: true
                  {{- end }}
                  {{- if .Values.extraVolumeMounts }}
                  {{- include "common.tplvalues.render" (dict "value" .Values.extraVolumeMounts "context" $) | nindent 12 }}
                  {{- end }}
                  {{- if .Values.controller.extraVolumeMounts }}
                  {{- include "common.tplvalues.render" (dict "value" .Values.controller.extraVolumeMounts "context" $) | nindent 12 }}
                  {{- end }}
                  - name: kafka-config-connect
                    mountPath: /opt/bitnami/kafka/config/connect-distributed.properties
                    subPath: connect-distributed.properties
                  - name: kafka-configmaps-connect
                    mountPath: /opt/bitnami/kafka/config/connector-config.json
                    subPath: connector-config.json
                  - name: scripts-connect
                    mountPath: /scripts-connect
              {{- if .Values.metrics.jmx.enabled }}
              - name: jmx-exporter
                image: {{ include "kafka.metrics.jmx.image" . }}
                imagePullPolicy: {{ .Values.metrics.jmx.image.pullPolicy | quote }}
                {{- if .Values.metrics.jmx.containerSecurityContext.enabled }}
                securityContext: {{- include "common.compatibility.renderSecurityContext" (dict "secContext" .Values.metrics.jmx.containerSecurityContext "context" $) | nindent 12 }}
                {{- end }}
                {{- if .Values.diagnosticMode.enabled }}
                command: {{- include "common.tplvalues.render" (dict "value" .Values.diagnosticMode.command "context" $) | nindent 12 }}
                args: {{- include "common.tplvalues.render" (dict "value" .Values.diagnosticMode.args "context" $) | nindent 12 }}
                {{- else }}
                command:
                  - java
                args:
                  - -XX:MaxRAMPercentage=100
                  - -XshowSettings:vm
                  - -jar
                  - jmx_prometheus_httpserver.jar
                  - {{ .Values.metrics.jmx.containerPorts.metrics | quote }}
                  - /etc/jmx-kafka/jmx-kafka-prometheus.yml
                {{- end }}
                ports:
                  - name: metrics
                    containerPort: {{ .Values.metrics.jmx.containerPorts.metrics }}
                {{- if .Values.metrics.jmx.resources }}
                resources: {{- toYaml .Values.metrics.jmx.resources | nindent 12 }}
                {{- else if ne .Values.metrics.jmx.resourcesPreset "none" }}
                resources: {{- include "common.resources.preset" (dict "type" .Values.metrics.jmx.resourcesPreset) | nindent 12 }}
                {{- end }}
                volumeMounts:
                  - name: jmx-config
                    mountPath: /etc/jmx-kafka
              {{- end }}
              {{- if .Values.controller.sidecars }}
              {{- include "common.tplvalues.render" (dict "value" .Values.controller.sidecars "context" $) | nindent 8 }}
              {{- end }}
              {{- if .Values.sidecars }}
              {{- include "common.tplvalues.render" (dict "value" .Values.sidecars "context" $) | nindent 8 }}
              {{- end }}
            volumes:
              - name: kafka-plugins
                emptyDir: {}
              - name: kafka-connectors
                emptyDir: {}
              - name: kafka-configmaps
                configMap:
                  name: {{ include "kafka.controller.configmapName" . }}
              - name: kafka-secret-config
              {{- if (include "kafka.controller.secretConfigExists" .) }}
                secret:
                  secretName: {{ include "kafka.controller.secretConfigName" . }}
              {{- else }}
                emptyDir: {}
              {{- end }}
              - name: kafka-config
                emptyDir: {}
              - name: tmp
                emptyDir: {}
              - name: scripts
                configMap:
                  name: {{ include "common.names.fullname" . }}-scripts
                  defaultMode: 493
              {{- if and .Values.externalAccess.enabled .Values.externalAccess.autoDiscovery.enabled }}
              - name: kafka-autodiscovery-shared
                emptyDir: {}
              {{- end }}
              {{- if or .Values.log4j .Values.existingLog4jConfigMap }}
              - name: log4j-config
                configMap:
                  name: {{ include "kafka.log4j.configMapName" . }}
              {{- end }}
              {{- if .Values.metrics.jmx.enabled }}
              - name: jmx-config
                configMap:
                  name: {{ include "kafka.metrics.jmx.configmapName" . }}
              {{- end }}
              {{- if or .Values.tls.zookeeper.enabled (include "kafka.sslEnabled" .) }}
              - name: kafka-shared-certs
                emptyDir: {}
              {{- if and (include "kafka.sslEnabled" .) (or .Values.tls.existingSecret .Values.tls.autoGenerated) }}
              - name: kafka-certs
                projected:
                  defaultMode: 256
                  sources:
                    - secret:
                        name: {{ include "kafka.tlsSecretName" . }}
                    {{- if .Values.tls.jksTruststoreSecret }}
                    - secret:
                        name: {{ .Values.tls.jksTruststoreSecret }}
                    {{- end }}
              {{- end }}
              {{- if and .Values.tls.zookeeper.enabled .Values.tls.zookeeper.existingSecret }}
              - name: kafka-zookeeper-cert
                secret:
                  secretName: {{ .Values.tls.zookeeper.existingSecret }}
                  defaultMode: 256
              {{- end }}
              {{- end }}
              - name: kafka-configmaps-connect
                configMap:
                  name: {{ include "common.names.fullname" . }}-controller-configuration-connect
              - name: kafka-config-connect
                emptyDir: {}
              - name: scripts-connect
                configMap:
                  name: {{ include "common.names.fullname" . }}-scripts-connect
                  defaultMode: 493
              {{- if .Values.extraVolumes }}
              {{- include "common.tplvalues.render" (dict "value" .Values.extraVolumes "context" $) | nindent 8 }}
              {{- end }}
              {{- if .Values.controller.extraVolumes }}
              {{- include "common.tplvalues.render" (dict "value" .Values.controller.extraVolumes "context" $) | nindent 8 }}
              {{- end }}
              {{- if not .Values.controller.persistence.enabled }}
              - name: data
                emptyDir: {}
              {{- else if .Values.controller.persistence.existingClaim }}
              - name: data
                persistentVolumeClaim:
                  claimName: {{ printf "%s" (tpl .Values.controller.persistence.existingClaim .) }}
              {{- end }}
              {{- if not .Values.controller.logPersistence.enabled }}
              - name: logs
                emptyDir: {}
              {{- else if .Values.controller.logPersistence.existingClaim }}
              - name: logs
                persistentVolumeClaim:
                  claimName: {{ printf "%s" (tpl .Values.controller.logPersistence.existingClaim .) }}
              {{- end }}
        {{- if or (and .Values.controller.persistence.enabled (not .Values.controller.persistence.existingClaim)) (and .Values.controller.logPersistence.enabled (not .Values.controller.logPersistence.existingClaim)) }}
        volumeClaimTemplates:
          {{- if and .Values.controller.persistence.enabled (not .Values.controller.persistence.existingClaim) }}
          - apiVersion: v1
            kind: PersistentVolumeClaim
            metadata:
              name: data
              {{- if .Values.controller.persistence.annotations }}
              annotations: {{- include "common.tplvalues.render" (dict "value" .Values.controller.persistence.annotations "context" $) | nindent 10 }}
              {{- end }}
              {{- if .Values.controller.persistence.labels }}
              labels: {{- include "common.tplvalues.render" (dict "value" .Values.controller.persistence.labels "context" $) | nindent 10 }}
              {{- end }}
            spec:
              accessModes:
              {{- range .Values.controller.persistence.accessModes }}
                - {{ . | quote }}
              {{- end }}
              resources:
                requests:
                  storage: {{ .Values.controller.persistence.size | quote }}
              {{- include "common.storage.class" (dict "persistence" .Values.controller.persistence "global" .Values.global) | nindent 8 }}
              {{- if .Values.controller.persistence.selector }}
              selector: {{- include "common.tplvalues.render" (dict "value" .Values.controller.persistence.selector "context" $) | nindent 10 }}
              {{- end -}}
          {{- end }}
          {{- if and .Values.controller.logPersistence.enabled (not .Values.controller.logPersistence.existingClaim) }}
          - apiVersion: v1
            kind: PersistentVolumeClaim
            metadata:
              name: logs
              {{- if .Values.controller.logPersistence.annotations }}
              annotations: {{- include "common.tplvalues.render" (dict "value" .Values.controller.logPersistence.annotations "context" $) | nindent 10 }}
              {{- end }}
            spec:
              accessModes:
              {{- range .Values.controller.logPersistence.accessModes }}
                - {{ . | quote }}
              {{- end }}
              resources:
                requests:
                  storage: {{ .Values.controller.logPersistence.size | quote }}
              {{- include "common.storage.class" (dict "persistence" .Values.controller.logPersistence "global" .Values.global) | nindent 8 }}
              {{- if .Values.controller.logPersistence.selector }}
              selector: {{- include "common.tplvalues.render" (dict "value" .Values.controller.logPersistence.selector "context" $) | nindent 10 }}
              {{- end -}}
          {{- end }}
        {{- end }}
      {{- end }}

    - |
      {{- $replicaCount := int .Values.controller.replicaCount }}
      {{- if and .Values.kraft.enabled (include "kafka.controller.createConfigmap" .) (gt $replicaCount 0)}}
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: {{ printf "%s-controller-configuration-connect" (include "common.names.fullname" .) }}
        labels: {{- include "common.labels.standard" ( dict "customLabels" .Values.commonLabels "context" $ ) | nindent 4 }}
          app.kubernetes.io/component: controller-eligible
          app.kubernetes.io/part-of: kafka
        {{- if .Values.commonAnnotations }}
        annotations: {{- include "common.tplvalues.render" ( dict "value" .Values.commonAnnotations "context" $ ) | nindent 4 }}
        {{- end }}
      data:
        connect-distributed.properties: |-
          bootstrap.servers={{ include "common.names.fullname" . }}.{{ include "common.names.namespace" . }}.svc.{{ .Values.clusterDomain }}:{{ .Values.listeners.client.port | default 9092 }}
          group.id=connect-cluster
          config.storage.topic=connect-configs
          offset.storage.topic=connect-offset
          status.storage.topic=connect-status
          key.converter=org.apache.kafka.connect.json.JsonConverter
          value.converter=org.apache.kafka.connect.json.JsonConverter
          plugin.path=/opt/connectors,/opt/bitnami/kafka/plugins
          # Additional configurations
          #listener.security.protocol.map={{ include "kafka.securityProtocolMap" . }}
          {{- if .Values.kraft.enabled }}
          {{- include "kafka.kraftConnectConfig" . | nindent 4 }}
          {{- end }}
          {{- if or .Values.zookeeper.enabled .Values.externalZookeeper.servers }}
          # Zookeeper configuration
          zookeeper.metadata.migration.enable=true
          inter.broker.protocol.version=3.4
          inter.broker.protocol.version={{ default (regexFind "^[0-9].[0-9]+" .Chart.AppVersion) .Values.interBrokerProtocolVersion }}
          {{- include "kafka.zookeeperConfig" . | nindent 4 }}
          {{- end }}

          # Common Kafka Configuration
          {{- include "kafka.commonConnectConfig" . | nindent 4 }}

          # Custom Kafka Configuration
          {{- include "common.tplvalues.render" ( dict "value" .Values.extraConfig "context" $ ) | nindent 4 }}
          {{- include "common.tplvalues.render" ( dict "value" .Values.controller.extraConfig "context" $ ) | nindent 4 }}
          {{- include "kafka.properties.render" (merge .Values.controller.extraConfigYaml .Values.extraConfigYaml) | nindent 4 }}
          ...
        mongodb.properties: |-
          connection.uri=mongodb://root:password@mongodb-hostname:27017
          ...
        connector-config.json: |  
        {{- with .Values.connectors }}
          {{- toYaml . | nindent 10 }}
        {{- end }}
      {{- end}}

    - |
      {{- $releaseNamespace := include "common.names.namespace" . }}
      {{- $fullname := include "common.names.fullname" . }}
      {{- $clusterDomain := .Values.clusterDomain }}
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: {{ printf "%s-scripts-connect" $fullname }}
        namespace: {{ $releaseNamespace  | quote }}
        labels: {{- include "common.labels.standard" ( dict "customLabels" .Values.commonLabels "context" $ ) | nindent 4 }}
        {{- if .Values.commonAnnotations }}
        annotations: {{- include "common.tplvalues.render" ( dict "value" .Values.commonAnnotations "context" $ ) | nindent 4 }}
        {{- end }}
      data:
        kafka-connectors.sh: |-
          #!/bin/bash
          
          # Path to the mounted ConfigMap file
          CONFIG_PATH="/opt/bitnami/kafka/config/connector-config.json"

          # Kafka Connect REST endpoint
          KAFKA_CONNECT_URL="http://{{ include "common.names.fullname" . }}-controller-connect-0:8083/connectors"

          # Maximum wait time (seconds)
          MAX_WAIT=60
          WAIT_INTERVAL=5
          WAITED=0
          
          echo "#######################"
          echo "Waiting for Kafka Connect to be ready..."

          # Loop to check if Kafka Connect is ready
          until curl -s "$KAFKA_CONNECT_URL" >/dev/null 2>&1; do
            # If Kafka Connect is still not ready, wait and retry
            echo "Kafka Connect is not ready yet. Retrying in $WAIT_INTERVAL seconds..."
            sleep $WAIT_INTERVAL
            WAITED=$((WAITED + WAIT_INTERVAL))
            
            # Check if the wait time has exceeded the maximum
            if [ "$WAITED" -ge "$MAX_WAIT" ]; then
              echo "Kafka Connect did not become ready within $MAX_WAIT seconds. Exiting."
              exit 1
            fi
          done

          # If Kafka Connect is ready, proceed to execute the desired script
          echo "Kafka Connect is ready. Executing connector load script..."
          sleep 30
          echo "###########################"
          echo "Configuring Kafka Connectors"

          CONFIG_PATH="/opt/bitnami/kafka/config/connector-config.json"
          # Check if jq is installed
          if ! command -v /opt/connectors/jq &> /dev/null; then
            echo "Error: jq is not installed. Please install jq to proceed."
            exit 1
          fi

          # Load connector configs and parse each item
          if [ -f "$CONFIG_PATH" ]; then
            connectors=$(cat "$CONFIG_PATH")
            
            # Use jq to parse and iterate through each connector config
            echo "$connectors" | /opt/connectors/jq -c '.[]' | while read -r connector; do
              # Extract connector name for log output
              connector_name=$(echo "$connector" | /opt/connectors/jq -r '.name')
              
              # Send the connector config to Kafka Connect
              response=$(curl -o /dev/null -w "%{http_code}" -X POST -H "Content-Type: application/json" --data "$connector" "$KAFKA_CONNECT_URL")

              if [ "$response" -eq 201 ]; then
                echo "Connector $connector_name loaded successfully."
              elif [ "$response" -eq 409 ]; then
                echo "Connector $connector_name already exists. Skipping."
              else
                echo "Failed to load connector $connector_name. HTTP response code: $response"
              fi
            done
          else
            echo "Config file not found at $CONFIG_PATH!"
            exit 1
          fi
          echo "Kafka Connectors configured successfully."
          echo "################"
          

        kafka-download.sh: |-
          #!/bin/bash
          mkdir -p /connectors/starrocks-kafka-connector-1.0.4
          curl --output /connectors/mongo-kafka-connect-1.13.1-all.jar --remote-name --location --silent https://search.maven.org/remotecontent?filepath=org/mongodb/kafka/mongo-kafka-connect/1.13.1/mongo-kafka-connect-1.13.1-all.jar
          curl --output /connectors/starrocks-kafka-connector-1.0.4.tar.gz  --remote-name --location --silent https://github.com/StarRocks/starrocks-connector-for-kafka/releases/download/v1.0.4/starrocks-kafka-connector-1.0.4.tar.gz && tar -xvzf  /connectors/starrocks-kafka-connector-1.0.4.tar.gz -C /connectors && rm /connectors/starrocks-kafka-connector-1.0.4.tar.gz
          curl --output /connectors/zilliz-kafka-connect-milvus-1.0.1.zip  --remote-name --location --silent https://github.com/zilliztech/kafka-connect-milvus/releases/download/v1.0.1/zilliz-kafka-connect-milvus-1.0.1.zip && unzip /connectors/zilliz-kafka-connect-milvus-1.0.1.zip -d /connectors && rm /connectors/zilliz-kafka-connect-milvus-1.0.1.zip
          curl --output /connectors/opensearch-connector-for-apache-kafka-3.1.1.zip  --remote-name --location --silent https://github.com/Aiven-Open/opensearch-connector-for-apache-kafka/releases/download/v3.1.1/opensearch-connector-for-apache-kafka-3.1.1.zip && unzip /connectors/opensearch-connector-for-apache-kafka-3.1.1.zip -d /connectors && rm /connectors/opensearch-connector-for-apache-kafka-3.1.1.zip
        kafka-init-connect.sh: |-
          #!/bin/bash

          set -o errexit
          set -o nounset
          set -o pipefail

          error(){
            local message="${1:?missing message}"
            echo "ERROR: ${message}"
            exit 1
          }

          retry_while() {
              local -r cmd="${1:?cmd is missing}"
              local -r retries="${2:-12}"
              local -r sleep_time="${3:-5}"
              local return_value=1

              read -r -a command <<< "$cmd"
              for ((i = 1 ; i <= retries ; i+=1 )); do
                  "${command[@]}" && return_value=0 && break
                  sleep "$sleep_time"
              done
              return $return_value
          }

          replace_in_file() {
              local filename="${1:?filename is required}"
              local match_regex="${2:?match regex is required}"
              local substitute_regex="${3:?substitute regex is required}"
              local posix_regex=${4:-true}

              local result

              # We should avoid using 'sed in-place' substitutions
              # 1) They are not compatible with files mounted from ConfigMap(s)
              # 2) We found incompatibility issues with Debian10 and "in-place" substitutions
              local -r del=$'\001' # Use a non-printable character as a 'sed' delimiter to avoid issues
              if [[ $posix_regex = true ]]; then
                  result="$(sed -E "s${del}${match_regex}${del}${substitute_regex}${del}g" "$filename")"
              else
                  result="$(sed "s${del}${match_regex}${del}${substitute_regex}${del}g" "$filename")"
              fi
              echo "$result" > "$filename"
          }
          kafka_conf_set() {
              local file="${1:?missing file}"
              local key="${2:?missing key}"
              local value="${3:?missing value}"

              # Check if the value was set before
              if grep -q "^[#\\s]*$key\s*=.*" "$file"; then
                  # Update the existing key
                  replace_in_file "$file" "^[#\\s]*${key}\s*=.*" "${key}=${value}" false
              else
                  # Add a new key
                  printf '\n%s=%s' "$key" "$value" >>"$file"
              fi
          }

          replace_placeholder() {
            local placeholder="${1:?missing placeholder value}"
            local password="${2:?missing password value}"
            sed -i "s/$placeholder/$password/g" "$KAFKA_CONFIG_FILE"
          }

          append_file_to_kafka_conf() {
              local file="${1:?missing source file}"
              local conf="${2:?missing kafka conf file}"

              cat "$1" >> "$2"
          }

          configure_external_access() {
            # Configure external hostname
            if [[ -f "/shared/external-host.txt" ]]; then
              host=$(cat "/shared/external-host.txt")
            elif [[ -n "${EXTERNAL_ACCESS_HOST:-}" ]]; then
              host="$EXTERNAL_ACCESS_HOST"
            elif [[ -n "${EXTERNAL_ACCESS_HOSTS_LIST:-}" ]]; then
              read -r -a hosts <<<"$(tr ',' ' ' <<<"${EXTERNAL_ACCESS_HOSTS_LIST}")"
              host="${hosts[$POD_ID]}"
            elif [[ "$EXTERNAL_ACCESS_HOST_USE_PUBLIC_IP" =~ ^(yes|true)$ ]]; then
              host=$(curl -s https://ipinfo.io/ip)
            else
              error "External access hostname not provided"
            fi

            # Configure external port
            if [[ -f "/shared/external-port.txt" ]]; then
              port=$(cat "/shared/external-port.txt")
            elif [[ -n "${EXTERNAL_ACCESS_PORT:-}" ]]; then
              if [[ "${EXTERNAL_ACCESS_PORT_AUTOINCREMENT:-}" =~ ^(yes|true)$ ]]; then
                port="$((EXTERNAL_ACCESS_PORT + POD_ID))"
              else
                port="$EXTERNAL_ACCESS_PORT"
              fi
            elif [[ -n "${EXTERNAL_ACCESS_PORTS_LIST:-}" ]]; then
              read -r -a ports <<<"$(tr ',' ' ' <<<"${EXTERNAL_ACCESS_PORTS_LIST}")"
              port="${ports[$POD_ID]}"
            else
              error "External access port not provided"
            fi
            # Configure Kafka advertised listeners
            sed -i -E "s|^(advertised\.listeners=\S+)$|\1,{{ upper .Values.listeners.external.name }}://${host}:${port}|" "$KAFKA_CONFIG_FILE"
          }
          {{- if (include "kafka.sslEnabled" .) }}
          configure_kafka_tls() {
            # Remove previously existing keystores and certificates, if any
            rm -f /certs/kafka.keystore.jks /certs/kafka.truststore.jks
            rm -f /certs/tls.crt /certs/tls.key /certs/ca.crt
            find /certs -name "xx*" -exec rm {} \;
            if [[ "${KAFKA_TLS_TYPE}" = "PEM" ]]; then
              # Copy PEM certificate and key
              if [[ -f "/mounted-certs/kafka-${POD_ROLE}-${POD_ID}.crt" && "/mounted-certs/kafka-${POD_ROLE}-${POD_ID}.key" ]]; then
                cp "/mounted-certs/kafka-${POD_ROLE}-${POD_ID}.crt" /certs/tls.crt
                # Copy the PEM key ensuring the key used PEM format with PKCS#8
                openssl pkcs8 -topk8 -nocrypt -in "/mounted-certs/kafka-${POD_ROLE}-${POD_ID}.key" > /certs/tls.key
              elif [[ -f /mounted-certs/kafka.crt && -f /mounted-certs/kafka.key ]]; then
                cp "/mounted-certs/kafka.crt" /certs/tls.crt
                # Copy the PEM key ensuring the key used PEM format with PKCS#8
                openssl pkcs8 -topk8 -nocrypt -in "/mounted-certs/kafka.key" > /certs/tls.key
              elif [[ -f /mounted-certs/tls.crt && -f /mounted-certs/tls.key ]]; then
                cp "/mounted-certs/tls.crt" /certs/tls.crt
                # Copy the PEM key ensuring the key used PEM format with PKCS#8
                openssl pkcs8 -topk8 -nocrypt -in "/mounted-certs/tls.key" > /certs/tls.key
              else
                error "PEM key and cert files not found"
              fi

              {{- if not .Values.tls.pemChainIncluded }}
              # Copy CA certificate
              if [[ -f /mounted-certs/kafka-ca.crt ]]; then
                cp /mounted-certs/kafka-ca.crt /certs/ca.crt
              elif [[ -f /mounted-certs/ca.crt ]]; then
                cp /mounted-certs/ca.crt /certs/ca.crt
              else
                error "CA certificate file not found"
              fi
              {{- else }}
              # CA certificates are also included in the same certificate
              # All public certs will be included in the truststore
              cp /certs/tls.crt /certs/ca.crt
              {{- end }}

              # Create JKS keystore from PEM cert and key
              openssl pkcs12 -export -in "/certs/tls.crt" \
                -passout pass:"${KAFKA_TLS_KEYSTORE_PASSWORD}" \
                -inkey "/certs/tls.key" \
                -out "/certs/kafka.keystore.p12"
              keytool -importkeystore -srckeystore "/certs/kafka.keystore.p12" \
                -srcstoretype PKCS12 \
                -srcstorepass "${KAFKA_TLS_KEYSTORE_PASSWORD}" \
                -deststorepass "${KAFKA_TLS_KEYSTORE_PASSWORD}" \
                -destkeystore "/certs/kafka.keystore.jks" \
                -noprompt
              # Create JKS truststore from CA cert
              keytool -keystore /certs/kafka.truststore.jks -alias CARoot -import -file /certs/ca.crt -storepass "${KAFKA_TLS_TRUSTSTORE_PASSWORD}" -noprompt
              # Remove extra files
              rm -f "/certs/kafka.keystore.p12" "/certs/tls.crt" "/certs/tls.key" "/certs/ca.crt"
            elif [[ "${KAFKA_TLS_TYPE}" = "JKS" ]]; then
              if [[ -f "/mounted-certs/kafka-${POD_ROLE}-${POD_ID}.keystore.jks" ]]; then
                cp "/mounted-certs/kafka-${POD_ROLE}-${POD_ID}.keystore.jks" /certs/kafka.keystore.jks
              elif [[ -f {{ printf "/mounted-certs/%s" ( default "kafka.keystore.jks" .Values.tls.jksKeystoreKey) | quote }} ]]; then
                cp {{ printf "/mounted-certs/%s" ( default "kafka.keystore.jks" .Values.tls.jksKeystoreKey) | quote }} /certs/kafka.keystore.jks
              else
                error "Keystore file not found"
              fi

              if [[ -f {{ printf "/mounted-certs/%s" ( default "kafka.truststore.jks" .Values.tls.jksTruststoreKey) | quote }} ]]; then
                cp {{ printf "/mounted-certs/%s" ( default "kafka.truststore.jks" .Values.tls.jksTruststoreKey) | quote }} /certs/kafka.truststore.jks
              else
                error "Truststore file not found"
              fi
            else
              error "Invalid type ${KAFKA_TLS_TYPE}"
            fi

            # Configure TLS password settings in Kafka configuration
            [[ -n "${KAFKA_TLS_KEYSTORE_PASSWORD:-}" ]] && kafka_conf_set "$KAFKA_CONFIG_FILE" "ssl.keystore.password" "$KAFKA_TLS_KEYSTORE_PASSWORD"
            [[ -n "${KAFKA_TLS_TRUSTSTORE_PASSWORD:-}" ]] && kafka_conf_set "$KAFKA_CONFIG_FILE" "ssl.truststore.password" "$KAFKA_TLS_TRUSTSTORE_PASSWORD"
            [[ -n "${KAFKA_TLS_PEM_KEY_PASSWORD:-}" ]] && kafka_conf_set "$KAFKA_CONFIG_FILE" "ssl.key.password" "$KAFKA_TLS_PEM_KEY_PASSWORD"
            # Avoid errors caused by previous checks
            true
          }
          {{- end }}
          {{- if and .Values.tls.zookeeper.enabled .Values.tls.zookeeper.existingSecret }}
          configure_zookeeper_tls() {
            # Remove previously existing keystores
            rm -f /certs/zookeeper.keystore.jks /certs/zookeeper.truststore.jks
            ZOOKEEPER_TRUSTSTORE={{ printf "/zookeeper-certs/%s" .Values.tls.zookeeper.existingSecretTruststoreKey | quote }}
            ZOOKEEPER_KEYSTORE={{ printf "/zookeeper-certs/%s" .Values.tls.zookeeper.existingSecretKeystoreKey | quote }}
            if [[ -f "$ZOOKEEPER_KEYSTORE" ]]; then
              cp "$ZOOKEEPER_KEYSTORE" "/certs/zookeeper.keystore.jks"
            else
              error "Zookeeper keystore file not found"
            fi
            if [[ -f "$ZOOKEEPER_TRUSTSTORE" ]]; then
              cp "$ZOOKEEPER_TRUSTSTORE" "/certs/zookeeper.truststore.jks"
            else
              error "Zookeeper keystore file not found"
            fi
            [[ -n "${KAFKA_ZOOKEEPER_TLS_KEYSTORE_PASSWORD:-}" ]] && kafka_conf_set "$KAFKA_CONFIG_FILE" "zookeeper.ssl.keystore.password" "${KAFKA_ZOOKEEPER_TLS_KEYSTORE_PASSWORD}"
            [[ -n "${KAFKA_ZOOKEEPER_TLS_TRUSTSTORE_PASSWORD:-}" ]] && kafka_conf_set "$KAFKA_CONFIG_FILE" "zookeeper.ssl.truststore.password" "${KAFKA_ZOOKEEPER_TLS_TRUSTSTORE_PASSWORD}"
            # Avoid errors caused by previous checks
            true
          }
          {{- end }}

          {{- if (include "kafka.saslEnabled" .) }}
          configure_kafka_sasl() {

            # Replace placeholders with passwords
            {{- if regexFind "SASL" (upper .Values.listeners.interbroker.protocol) }}
            {{- if (include "kafka.saslUserPasswordsEnabled" .) }}
            replace_placeholder "interbroker-password-placeholder" "$KAFKA_INTER_BROKER_PASSWORD"
            {{- end }}
            {{- if (include "kafka.saslClientSecretsEnabled" .) }}
            replace_placeholder "interbroker-client-secret-placeholder" "$KAFKA_INTER_BROKER_CLIENT_SECRET"
            {{- end }}
            {{- end -}}
            {{- if and .Values.kraft.enabled (regexFind "SASL" (upper .Values.listeners.controller.protocol)) }}
            {{- if (include "kafka.saslUserPasswordsEnabled" .) }}
            replace_placeholder "controller-password-placeholder" "$KAFKA_CONTROLLER_PASSWORD"
            {{- end }}
            {{- if (include "kafka.saslClientSecretsEnabled" .) }}
            replace_placeholder "controller-client-secret-placeholder" "$KAFKA_CONTROLLER_CLIENT_SECRET"
            {{- end }}
            {{- end }}
            {{- if (include "kafka.client.saslEnabled" .)}}
            read -r -a passwords <<<"$(tr ',;' ' ' <<<"${KAFKA_CLIENT_PASSWORDS:-}")"
            for ((i = 0; i < ${#passwords[@]}; i++)); do
                replace_placeholder "password-placeholder-${i}\"" "${passwords[i]}\""
            done
            {{- end }}
            {{- if .Values.sasl.zookeeper.user }}
            replace_placeholder "zookeeper-password-placeholder" "$KAFKA_ZOOKEEPER_PASSWORD"
            {{- end }}
          }
          {{- end }}

          {{- if .Values.externalAccess.autoDiscovery.enabled }}
          # Wait for autodiscovery to finish
          if [[ "${EXTERNAL_ACCESS_ENABLED:-false}" =~ ^(yes|true)$ ]]; then
            retry_while "test -f /shared/external-host.txt -o -f /shared/external-port.txt" || error "Timed out waiting for autodiscovery init-container"
          fi
          {{- end }}

          {{- if .Values.sasl.zookeeper.user }}
          export KAFKA_CONFIG_FILE=/config/kafka_jaas.conf
          cat << EOF > /config/kafka_jaas.conf
          Client {
            org.apache.kafka.common.security.plain.PlainLoginModule required
            username="{{ .Values.sasl.zookeeper.user }}"
            password="zookeeper-password-placeholder";
          };
          EOF
          replace_placeholder "zookeeper-password-placeholder" "$KAFKA_ZOOKEEPER_PASSWORD"
          {{- end }}

          export KAFKA_CONFIG_FILE=/config-connect/connect-distributed.properties
          cp /configmaps-connect/connect-distributed.properties $KAFKA_CONFIG_FILE

          # Get pod ID and role, last and second last fields in the pod name respectively
          POD_ID=$(echo "$MY_POD_NAME" | rev | cut -d'-' -f 1 | rev)
          POD_ROLE=$(echo "$MY_POD_NAME" | rev | cut -d'-' -f 2 | rev)

          # Configure node.id and/or broker.id
          if [[ -f "/bitnami/kafka/data/meta.properties" ]]; then
              if grep -q "broker.id" /bitnami/kafka/data/meta.properties; then
                ID="$(grep "broker.id" /bitnami/kafka/data/meta.properties | awk -F '=' '{print $2}') + {{ .Values.controller.replicaCount | default 0 }}"
                {{- if or (and .Values.kraft.enabled (not .Values.broker.zookeeperMigrationMode)) (and (not .Values.zookeeper.enabled) (not .Values.externalZookeeper.servers)) }}
                kafka_conf_set "$KAFKA_CONFIG_FILE" "node.id" "$ID"
                {{- else }}
                kafka_conf_set "$KAFKA_CONFIG_FILE" "broker.id" "$ID"
                {{- end }}
              else
                ID="$(grep "node.id" /bitnami/kafka/data/meta.properties | awk -F '=' '{print $2}') + {{ .Values.controller.replicaCount | default 0 }}"
                kafka_conf_set "$KAFKA_CONFIG_FILE" "node.id" "$ID"
              fi
          else
              ID=$((POD_ID + KAFKA_MIN_ID + {{ .Values.controller.replicaCount | default 0 }}))
              {{- if .Values.kraft.enabled }}
              kafka_conf_set "$KAFKA_CONFIG_FILE" "node.id" "$ID"
              {{- end }}
              {{- if or .Values.zookeeper.enabled .Values.externalZookeeper.servers }}
              kafka_conf_set "$KAFKA_CONFIG_FILE" "broker.id" "$ID"
              {{- end }}
          fi
          {{- if not .Values.listeners.advertisedListeners }}
          replace_placeholder "advertised-address-placeholder" "${MY_POD_NAME}.{{ $fullname }}-${POD_ROLE}-headless.{{ $releaseNamespace }}.svc.{{ $clusterDomain }}"
          if [[ "${EXTERNAL_ACCESS_ENABLED:-false}" =~ ^(yes|true)$ ]]; then
            configure_external_access
          fi
          {{- end }}
          {{- if (include "kafka.sslEnabled" .) }}
          configure_kafka_tls
          {{- end }}
          {{- if (include "kafka.saslEnabled" .) }}
          configure_kafka_sasl
          {{- end }}
          {{- if and .Values.tls.zookeeper.enabled .Values.tls.zookeeper.existingSecret }}
          configure_zookeeper_tls
          {{- end }}
          {{- if eq .Values.brokerRackAssignment "aws-az" }}
          # Broker rack awareness
          echo "Obtaining broker.rack for aws-az rack assignment"
          EC2_METADATA_TOKEN=$(curl -X PUT "http://169.254.169.254/latest/api/token" -H "X-aws-ec2-metadata-token-ttl-seconds: 60")
          export BROKER_RACK=$(curl -H "X-aws-ec2-metadata-token: $EC2_METADATA_TOKEN" "http://169.254.169.254/latest/meta-data/placement/availability-zone-id")
          kafka_conf_set "$KAFKA_CONFIG_FILE" "broker.rack" "$BROKER_RACK"
          {{- end }}
          if [ -f /secret-config/server-secret.properties ]; then
            append_file_to_kafka_conf /secret-config/server-secret.properties $KAFKA_CONFIG_FILE
          fi


    - |
      apiVersion: v1
      kind: Service
      metadata:
        name: {{ include "common.names.fullname" . }}-xconnect
        labels: {{- include "common.labels.standard" ( dict "customLabels" .Values.commonLabels "context" $ ) | nindent 4 }}
          app.kubernetes.io/component: connector
      spec:
        ports:
          - protocol: TCP
            port: 8083
            targetPort: connector
        selector: {{- include "common.labels.matchLabels" ( dict "customLabels" .Values.commonLabels "context" $ ) | nindent 4 }}
          app.kubernetes.io/component: connector
